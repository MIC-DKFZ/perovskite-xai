{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c2f3db-3301-4aec-ab79-2df21f9c703e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pfs/work7/workspace/scratch/rk3078-WorkSpace04a/ExperimentalData/insitu/01_croppedData\n"
     ]
    }
   ],
   "source": [
    "cd /pfs/work7/workspace/scratch/rk3078-WorkSpace04a/ExperimentalData/insitu/01_croppedData/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c2e1a54-a6e0-4852-a06e-72a9bc79fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pandas import HDFStore\n",
    "\n",
    "# path to dataset saved as hdf5 file\n",
    "dataset_path = 'hdf5/'\n",
    "dataset_filename = 'dataset.hdf5'\n",
    "\n",
    "# specify folder name in which the dataset will be saved in the form of multiple npy-files  \n",
    "foldername='extracted_numpy'  \n",
    "save_path=dataset_path+foldername+\"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dca8ed2d-40df-4e60-a6b6-39e23f2c8118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:30<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [01:09<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# open h5py file\n",
    "with h5py.File(dataset_path+ dataset_filename, 'r') as f:\n",
    "    \n",
    "    # iterate through the subsets \"test\" and \"train\"\n",
    "    for subset in list(f.keys()):\n",
    "        print(subset)\n",
    "       \n",
    "        # iterate through all groups in current subset\n",
    "        for substrate in tqdm(list(f[subset].keys())):\n",
    "            \n",
    "            # if current group is contains substrate data, i.e. starts with \"A\", interate through all datasets (which contain data of the patches) \n",
    "            if substrate[0]==\"A\":\n",
    "                \n",
    "                for patch in list(f[subset+\"/\"+substrate].keys()):\n",
    "                    path=subset+\"/\"+substrate+\"/\"+patch\n",
    "                    \n",
    "                    dir_to_make=save_path+subset+\"/\"+substrate+\"/\"\n",
    "                    if not os.path.exists(dir_to_make):\n",
    "                        os.makedirs(dir_to_make)\n",
    "                        \n",
    "                    # save content of current dataset as npy-file contianing data of current patch\n",
    "                    np.save(save_path+path+\".npy\", np.array(f[path]).astype('uint16'))\n",
    "               \n",
    "                    \n",
    "# use HDFStore function to extract panda dataframes from hdf5 file        \n",
    "hdf =HDFStore(dataset_path+ 'dataset.hdf5', mode='r')\n",
    "\n",
    "labels_test=hdf.get('test/labels')\n",
    "labels_train=hdf.get('train/labels')\n",
    "\n",
    "fold0_train=hdf.get('train/cv_splits_5fold/fold0/train')\n",
    "fold0_val=hdf.get('train/cv_splits_5fold/fold0/val')\n",
    "fold1_train=hdf.get('train/cv_splits_5fold/fold1/train')\n",
    "fold1_val=hdf.get('train/cv_splits_5fold/fold1/val')\n",
    "fold2_train=hdf.get('train/cv_splits_5fold/fold2/train')\n",
    "fold2_val=hdf.get('train/cv_splits_5fold/fold2/val')\n",
    "fold3_train=hdf.get('train/cv_splits_5fold/fold3/train')\n",
    "fold3_val=hdf.get('train/cv_splits_5fold/fold3/val')\n",
    "fold4_train=hdf.get('train/cv_splits_5fold/fold4/train')\n",
    "fold4_val=hdf.get('train/cv_splits_5fold/fold4/val')\n",
    "\n",
    "hdf.close()\n",
    "\n",
    "# generate direcotries to save information regarding cross-validation splits\n",
    "for ix in range(5):\n",
    "    dir_to_make=save_path+\"train/cv_splits_5fold/fold\"+str(ix)\n",
    "    if not os.path.exists(dir_to_make):\n",
    "        os.makedirs(dir_to_make)\n",
    "        \n",
    "# save pandas dataframe to csv files        \n",
    "labels_test.to_csv(os.path.join(save_path+'test/', 'labels.csv'), index=False)\n",
    "labels_train.to_csv(os.path.join(save_path+'train/', 'labels.csv'), index=False)\n",
    "\n",
    "fold0_train.to_csv(os.path.join(save_path+'train/cv_splits_5fold/fold0/', 'train.csv'), index=False)\n",
    "fold0_val.to_csv(os.path.join(save_path+'train/cv_splits_5fold/fold0/', 'val.csv'), index=False)\n",
    "fold1_train.to_csv(os.path.join(save_path+'train/cv_splits_5fold/fold1/', 'train.csv'), index=False)\n",
    "fold1_val.to_csv(os.path.join(save_path+'train/cv_splits_5fold/fold1/', 'val.csv'), index=False)\n",
    "fold2_train.to_csv(os.path.join(save_path+'train/cv_splits_5fold/fold2/', 'train.csv'), index=False)\n",
    "fold2_val.to_csv(os.path.join(save_path+'train/cv_splits_5fold/fold2/', 'val.csv'), index=False)\n",
    "fold3_train.to_csv(os.path.join(save_path+'train/cv_splits_5fold/fold3/', 'train.csv'), index=False)\n",
    "fold3_val.to_csv(os.path.join(save_path+'train/cv_splits_5fold/fold3/', 'val.csv'), index=False)\n",
    "fold4_train.to_csv(os.path.join(save_path+'train/cv_splits_5fold/fold4/', 'train.csv'), index=False)\n",
    "fold4_val.to_csv(os.path.join(save_path+'train/cv_splits_5fold/fold4/', 'val.csv'), index=False)  \n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3d964c42-8172-4151-b295-b8a4a4bc84ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7920f49-f699-4ea8-a7c2-98c3b9cc1751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
