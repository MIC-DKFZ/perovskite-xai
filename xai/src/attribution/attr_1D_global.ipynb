{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir(Path(os.getcwd()).parents[2])\n",
    "os.getcwd()\n",
    "\n",
    "target = \"mth\"  # mth, pce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from captum.attr import GradientShap, IntegratedGradients, GuidedBackprop, GuidedGradCam\n",
    "from captum.metrics import sensitivity_max, infidelity\n",
    "from os.path import join\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from data.perovskite_dataset import PerovskiteDataset1d\n",
    "from models.resnet import ResNet152, ResNet, BasicBlock, Bottleneck\n",
    "from data.augmentations.perov_1d import normalize\n",
    "from base_model import seed_worker\n",
    "\n",
    "data_dir = os.getcwd() + \"/preprocessed\"\n",
    "\n",
    "if target == \"pce\":\n",
    "    checkpoint_dir = (\n",
    "        \"/home/l727n/E132-Projekte/Projects/Helmholtz_Imaging_ACVL/KIT-FZJ_2021_Perovskite/data_Jan_2022/checkpoints\"\n",
    "    )\n",
    "\n",
    "    path_to_checkpoint = join(checkpoint_dir, \"1D-epoch=999-val_MAE=0.000-train_MAE=0.490.ckpt\")\n",
    "else:\n",
    "    checkpoint_dir = \"/home/l727n/E132-Projekte/Projects/Helmholtz_Imaging_ACVL/KIT-FZJ_2021_Perovskite/data_Jan_2022/mT_checkpoints/checkpoints\"\n",
    "\n",
    "    path_to_checkpoint = join(checkpoint_dir, \"mT_1D_RN152_full-epoch=999-val_MAE=0.000-train_MAE=40.332.ckpt\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1D Model (no border)\n",
    "\n",
    "hypparams = {\n",
    "    \"dataset\": \"Perov_1d\",\n",
    "    \"dims\": 1,\n",
    "    \"bottleneck\": False,\n",
    "    \"name\": \"ResNet152\",\n",
    "    \"data_dir\": data_dir,\n",
    "    \"no_border\": False,\n",
    "    \"resnet_dropout\": 0.0,\n",
    "    \"stochastic_depth\": 0.0,\n",
    "    \"norm_target\": True if target == \"pce\" else False,\n",
    "    \"target\": \"PCE_mean\" if target == \"pce\" else \"meanThickness\",\n",
    "}\n",
    "\n",
    "model = ResNet.load_from_checkpoint(\n",
    "    path_to_checkpoint,\n",
    "    block=BasicBlock,\n",
    "    num_blocks=[4, 13, 55, 4],\n",
    "    num_classes=1,\n",
    "    hypparams=hypparams,\n",
    ")\n",
    "\n",
    "print(\"Loaded\")\n",
    "model.eval()\n",
    "\n",
    "test_set = PerovskiteDataset1d(\n",
    "    data_dir,\n",
    "    transform=normalize(model.train_mean, model.train_std),\n",
    "    scaler=model.scaler,\n",
    "    no_border=False,\n",
    "    return_unscaled=False if target == \"pce\" else True,\n",
    "    label=\"PCE_mean\" if target == \"pce\" else \"meanThickness\",\n",
    "    fold=None,\n",
    "    split=\"test\",\n",
    "    val=False,\n",
    ")\n",
    "\n",
    "train_set = PerovskiteDataset1d(\n",
    "    data_dir,\n",
    "    transform=normalize(model.train_mean, model.train_std),\n",
    "    scaler=model.scaler,\n",
    "    no_border=False,\n",
    "    return_unscaled=False if target == \"pce\" else True,\n",
    "    label=\"PCE_mean\" if target == \"pce\" else \"meanThickness\",\n",
    ")\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "loader = DataLoader(\n",
    "    torch.utils.data.ConcatDataset([train_set, test_set]),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    worker_init_fn=seed_worker,\n",
    "    persistent_workers=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select batch\n",
    "x_batch = next(iter(loader))\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_batch = model.predict(x_batch).flatten()\n",
    "\n",
    "x_batch = x_batch[0]\n",
    "\n",
    "# Init pertubation function for infidelity metric\n",
    "\n",
    "std_noise = 0.01\n",
    "\n",
    "\n",
    "def perturb_fn(inputs):\n",
    "    noise = torch.tensor(np.random.normal(0, std_noise, inputs.shape)).float()\n",
    "    return noise, inputs - noise\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Attribution Computation and Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = GradientShap(model)\n",
    "attr_sum = []\n",
    "infid_sum = []\n",
    "sens_sum = []\n",
    "\n",
    "for n in tqdm(range(x_batch.shape[0])):\n",
    "    attr = method.attribute(\n",
    "        x_batch[n].unsqueeze(0),\n",
    "        n_samples=80,\n",
    "        stdevs=0.001,\n",
    "        baselines=x_batch,\n",
    "        target=0,\n",
    "    )\n",
    "\n",
    "    attr_sum.append(attr.abs())\n",
    "\n",
    "    infid_sum.append(infidelity(model, perturb_fn, x_batch[n].unsqueeze(0), attr))\n",
    "    sens_sum.append(sensitivity_max(method.attribute, x_batch[n].unsqueeze(0), target=0, baselines=x_batch))\n",
    "\n",
    "attr_eg = torch.cat(attr_sum).mean(dim=0)\n",
    "infid_eg = torch.Tensor(infid_sum).mean()\n",
    "sens_eg = torch.Tensor(sens_sum).mean()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = IntegratedGradients(model)\n",
    "attr_sum = []\n",
    "infid_sum = []\n",
    "sens_sum = []\n",
    "\n",
    "for n in tqdm(range(x_batch.shape[0])):\n",
    "    attr, delta = method.attribute(\n",
    "        x_batch[n].unsqueeze(0),\n",
    "        baselines=x_batch[n].unsqueeze(0) * 0,\n",
    "        return_convergence_delta=True,\n",
    "    )\n",
    "\n",
    "    attr_sum.append(attr.abs())\n",
    "\n",
    "    infid_sum.append(infidelity(model, perturb_fn, x_batch[n].unsqueeze(0), attr))\n",
    "    sens_sum.append(\n",
    "        sensitivity_max(\n",
    "            method.attribute,\n",
    "            x_batch[n].unsqueeze(0),\n",
    "            target=0,\n",
    "            baselines=x_batch[n].unsqueeze(0) * 0,\n",
    "        )\n",
    "    )\n",
    "\n",
    "attr_ig = torch.cat(attr_sum).mean(dim=0)\n",
    "infid_ig = torch.Tensor(infid_sum).mean()\n",
    "sens_ig = torch.Tensor(sens_sum).mean()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guided Backprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = GuidedBackprop(model)\n",
    "attr_sum = []\n",
    "infid_sum = []\n",
    "sens_sum = []\n",
    "\n",
    "for n in tqdm(range(x_batch.shape[0])):\n",
    "    attr = method.attribute(x_batch[n].unsqueeze(0), target=0)\n",
    "\n",
    "    attr_sum.append(attr.abs())\n",
    "\n",
    "    infid_sum.append(infidelity(model, perturb_fn, x_batch[n].unsqueeze(0), attr))\n",
    "    sens_sum.append(sensitivity_max(method.attribute, x_batch[n].unsqueeze(0)))\n",
    "\n",
    "attr_gbp = torch.cat(attr_sum).mean(dim=0)\n",
    "infid_gbp = torch.Tensor(infid_sum).mean()\n",
    "sens_gbp = torch.Tensor(sens_sum).mean()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guided GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = GuidedGradCam(model, model.layer4)\n",
    "attr_sum = []\n",
    "infid_sum = []\n",
    "sens_sum = []\n",
    "\n",
    "for n in tqdm(range(x_batch.shape[0])):\n",
    "    attr = method.attribute(x_batch[n].unsqueeze(0), target=0)\n",
    "\n",
    "    attr_sum.append(attr.detach().abs())\n",
    "\n",
    "    infid_sum.append(infidelity(model, perturb_fn, x_batch[n].unsqueeze(0), attr))\n",
    "    sens_sum.append(sensitivity_max(method.attribute, x_batch[n].unsqueeze(0)))\n",
    "\n",
    "attr_ggc = torch.cat(attr_sum).mean(dim=0)\n",
    "infid_ggc = torch.Tensor(infid_sum).mean()\n",
    "sens_ggc = torch.Tensor(sens_sum).mean()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Paper Vis ####\n",
    "color = [\"#E1462C\", \"#0059A0\", \"#5F3893\", \"#FF8777\", \"#0A2C6E\", \"#CEDEEB\"]\n",
    "filter = [\"ND\", \"LP725\", \"LP780\", \"SP775\"]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=1,\n",
    "    specs=[\n",
    "        [{\"secondary_y\": True}],\n",
    "    ],\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=np.abs(attr_eg.squeeze().sum(axis=0)),\n",
    "        name=\"Attribution\",\n",
    "        marker_color=color[2],\n",
    "        showlegend=False,\n",
    "        # marker_line_width=0.0,\n",
    "        stackgroup=\"one\",\n",
    "    ),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "x = x_batch.mean(0)\n",
    "\n",
    "for i in range(4):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            y=x[i],\n",
    "            name=filter[i],\n",
    "            opacity=0.5,\n",
    "            marker_color=\"grey\",\n",
    "            line=dict(width=2.5, dash=\"dot\") if i == 0 else dict(width=2.5),\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "fig.update_yaxes(\n",
    "    title=\"Intensity\",\n",
    "    showticklabels=True,\n",
    "    range=[-2.05, 2.05],\n",
    "    tickfont=dict(size=14, family=\"Helvetica\", color=\"rgb(0,0,0)\"),\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    zeroline=False,\n",
    "    title_text=\" \",\n",
    "    showticklabels=True,\n",
    "    showgrid=False,\n",
    "    secondary_y=True,\n",
    "    range=[0, 0.24],\n",
    "    tickvals=[0, 0.06, 0.12, 0.18, 0.24],\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    zeroline=False, title=\"Timesteps\", showgrid=False, tickfont=dict(size=14, family=\"Helvetica\", color=\"rgb(0,0,0)\")\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    "    bargap=0,\n",
    "    bargroupgap=0,\n",
    "    legend_title=\" \",\n",
    "    template=\"plotly_white\",\n",
    "    height=400,\n",
    "    width=700,\n",
    ")\n",
    "\n",
    "fig.write_image(\"xai/images/\" + target + \"/1D/1D_paper.png\", scale=2)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Large Overview Figure ####\n",
    "\n",
    "\n",
    "def format_title(title, subtitle=None, subtitle_font_size=14):\n",
    "    title = f\"<b>{title}</b>\"\n",
    "    if not subtitle:\n",
    "        return title\n",
    "    subtitle = f'<span style=\"font-size: {subtitle_font_size}px;\">{subtitle}</span>'\n",
    "    return f\"{title}<br>{subtitle}\"\n",
    "\n",
    "\n",
    "filter = [\"ND\", \"LP725\", \"LP780\", \"SP775\"]\n",
    "\n",
    "x = x_batch.mean(0)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=2,\n",
    "    specs=[\n",
    "        [{\"secondary_y\": True}, {\"secondary_y\": True}],\n",
    "        [{\"secondary_y\": True}, {\"secondary_y\": True}],\n",
    "    ],\n",
    "    subplot_titles=(\n",
    "        format_title(\n",
    "            \"\",\n",
    "            \"Expected Gradients (\"\n",
    "            + str(np.round(infid_eg.numpy(), 4))\n",
    "            + \", \"\n",
    "            + str(np.round(sens_eg.numpy(), 4))\n",
    "            + \")\",\n",
    "        ),\n",
    "        format_title(\n",
    "            \"\",\n",
    "            \"Integrated Gradients (\"\n",
    "            + str(np.round(infid_ig.numpy(), 4))\n",
    "            + \", \"\n",
    "            + str(np.round(sens_ig.numpy(), 4))\n",
    "            + \")\",\n",
    "        ),\n",
    "        format_title(\n",
    "            \"\",\n",
    "            \"Guided Backprop (\" + str(np.round(infid_gbp.numpy(), 4)) + \", \" + str(np.round(sens_gbp.numpy(), 4)) + \")\",\n",
    "        ),\n",
    "        format_title(\n",
    "            \"\",\n",
    "            \"Guided GradCAM (\" + str(np.round(infid_ggc.numpy(), 4)) + \", \" + str(np.round(sens_ggc.numpy(), 4)) + \")\",\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "for row in range(2):\n",
    "    for col in range(2):\n",
    "        for i in range(4):\n",
    "            fig.add_trace(\n",
    "                go.Scatter(y=x[i], name=filter[i], marker_color=\"grey\", opacity=0.3, showlegend=False),\n",
    "                row=row + 1,\n",
    "                col=col + 1,\n",
    "            )\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        y=attr_eg.squeeze().sum(axis=0),\n",
    "        marker_color=\"#042940\",\n",
    "        opacity=0.5,\n",
    "        showlegend=False,\n",
    "        marker_line_width=0,\n",
    "    ),\n",
    "    secondary_y=True,\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        y=attr_ig.squeeze().sum(axis=0),\n",
    "        marker_color=\"#005C53\",\n",
    "        opacity=0.5,\n",
    "        showlegend=False,\n",
    "        marker_line_width=0,\n",
    "    ),\n",
    "    secondary_y=True,\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        y=attr_gbp.squeeze().sum(axis=0),\n",
    "        marker_color=\"#9FC131\",\n",
    "        opacity=0.5,\n",
    "        showlegend=False,\n",
    "        marker_line_width=0,\n",
    "    ),\n",
    "    secondary_y=True,\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        y=attr_ggc.squeeze().sum(axis=0),\n",
    "        marker_color=\"#DBF227\",\n",
    "        opacity=0.5,\n",
    "        showlegend=False,\n",
    "        marker_line_width=0,\n",
    "    ),\n",
    "    secondary_y=True,\n",
    "    row=2,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.update_yaxes(title_text=None, secondary_y=True)\n",
    "fig.update_yaxes(title=\"Intensity\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Attribution\", secondary_y=True, row=1, col=2)\n",
    "fig.update_yaxes(title=\"Intensity\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Attribution\", secondary_y=True, row=2, col=2)\n",
    "\n",
    "fig.update_xaxes(title=None)\n",
    "fig.update_xaxes(title=\"Timesteps\", row=2, col=1)\n",
    "fig.update_xaxes(title=\"Timesteps\", row=2, col=2)\n",
    "\n",
    "if target == \"pce\":\n",
    "    subtitle = \"Perovskite 1D Model / Target: PCE /(mean Infidelity, mean Sensitivity)\"\n",
    "else:\n",
    "    subtitle = \"Perovskite 1D Model / Target: Mean Thickness / (mean Infidelity, mean Sensitivity)\"\n",
    "\n",
    "fig.update_layout(\n",
    "    title=format_title(\n",
    "        \"Global Attribution: Mean abs. Attribution (n = \" + str(batch_size) + \")\",\n",
    "        subtitle=subtitle,\n",
    "    ),\n",
    "    legend_title=None,\n",
    "    title_y=0.965,\n",
    "    title_x=0.035,\n",
    "    template=\"plotly_white\",\n",
    "    height=500,\n",
    "    width=1000,\n",
    ")\n",
    "\n",
    "fig.write_image(\"xai/images/\" + target + \"/1D/1D_cmp_global.png\", scale=2)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter Importance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_p_value_annotation(\n",
    "    fig, array_columns, p_value, subplot=None, _format=dict(interline=0.07, text_height=1.07, color=\"black\")\n",
    "):\n",
    "    \"\"\"Adds notations giving the p-value between two box plot data (t-test two-sided comparison)\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    fig: figure\n",
    "        plotly boxplot figure\n",
    "    array_columns: np.array\n",
    "        array of which columns to compare\n",
    "        e.g.: [[0,1], [1,2]] compares column 0 with 1 and 1 with 2\n",
    "    subplot: None or int\n",
    "        specifies if the figures has subplots and what subplot to add the notation to\n",
    "    _format: dict\n",
    "        format characteristics for the lines\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    fig: figure\n",
    "        figure with the added notation\n",
    "    \"\"\"\n",
    "    # Specify in what y_range to plot for each pair of columns\n",
    "    y_range = np.zeros([len(array_columns), 2])\n",
    "    for i in range(len(array_columns)):\n",
    "        y_range[i] = [1.01 + i * _format[\"interline\"], 1.02 + i * _format[\"interline\"]]\n",
    "\n",
    "    # Get values from figure\n",
    "    fig_dict = fig.to_dict()\n",
    "\n",
    "    # Get indices if working with subplots\n",
    "    if subplot:\n",
    "        if subplot == 1:\n",
    "            subplot_str = \"\"\n",
    "        else:\n",
    "            subplot_str = str(subplot)\n",
    "        indices = []  # Change the box index to the indices of the data for that subplot\n",
    "        for index, data in enumerate(fig_dict[\"data\"]):\n",
    "            # print(index, data['xaxis'], 'x' + subplot_str)\n",
    "            if data[\"xaxis\"] == \"x\" + subplot_str:\n",
    "                indices = np.append(indices, index)\n",
    "        indices = [int(i) for i in indices]\n",
    "        print((indices))\n",
    "    else:\n",
    "        subplot_str = \"\"\n",
    "\n",
    "    # Print the p-values\n",
    "    for index, column_pair in enumerate(array_columns):\n",
    "        # Mare sure it is selecting the data and subplot you want\n",
    "        # print('0:', fig_dict['data'][data_pair[0]]['name'], fig_dict['data'][data_pair[0]]['xaxis'])\n",
    "        # print('1:', fig_dict['data'][data_pair[1]]['name'], fig_dict['data'][data_pair[1]]['xaxis'])\n",
    "\n",
    "        # Get the p-value\n",
    "        pvalue = p_value[index]\n",
    "        if pvalue >= 0.1:\n",
    "            symbol = \"ns\"\n",
    "        elif pvalue >= 0.05:\n",
    "            symbol = \"*\"\n",
    "        elif pvalue >= 0.01:\n",
    "            symbol = \"**\"\n",
    "        else:\n",
    "            symbol = \"***\"\n",
    "        # # Vertical line\n",
    "        fig.add_shape(\n",
    "            type=\"line\",\n",
    "            xref=\"x\" + subplot_str,\n",
    "            yref=\"y\" + subplot_str + \" domain\",\n",
    "            x0=column_pair[0],\n",
    "            y0=y_range[index][0] + 0.01,\n",
    "            x1=column_pair[0],\n",
    "            y1=y_range[index][1] - 0.03,\n",
    "            line=dict(\n",
    "                color=_format[\"color\"],\n",
    "                width=2,\n",
    "            ),\n",
    "        )\n",
    "        # Horizontal line\n",
    "        fig.add_shape(\n",
    "            type=\"line\",\n",
    "            xref=\"x\" + subplot_str,\n",
    "            yref=\"y\" + subplot_str + \" domain\",\n",
    "            x0=column_pair[0],\n",
    "            y0=y_range[index][1],\n",
    "            x1=column_pair[1],\n",
    "            y1=y_range[index][1],\n",
    "            line=dict(\n",
    "                color=_format[\"color\"],\n",
    "                width=2,\n",
    "            ),\n",
    "        )\n",
    "        # #Vertical line\n",
    "        fig.add_shape(\n",
    "            type=\"line\",\n",
    "            xref=\"x\" + subplot_str,\n",
    "            yref=\"y\" + subplot_str + \" domain\",\n",
    "            x0=column_pair[1],\n",
    "            y0=y_range[index][0] + 0.01,\n",
    "            x1=column_pair[1],\n",
    "            y1=y_range[index][1] - 0.03,\n",
    "            line=dict(\n",
    "                color=_format[\"color\"],\n",
    "                width=2,\n",
    "            ),\n",
    "        )\n",
    "        ## add text at the correct x, y coordinates\n",
    "        ## for bars, there is a direct mapping from the bar number to 0, 1, 2...\n",
    "        fig.add_annotation(\n",
    "            dict(\n",
    "                font=dict(color=_format[\"color\"], size=14),\n",
    "                x=(column_pair[0] + column_pair[1]) / 2,\n",
    "                y=y_range[index][1] * _format[\"text_height\"],\n",
    "                showarrow=False,\n",
    "                text=symbol,\n",
    "                textangle=0,\n",
    "                xref=\"x\" + subplot_str,\n",
    "                yref=\"y\" + subplot_str + \" domain\",\n",
    "            )\n",
    "        )\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"mth\"\n",
    "color = [\"#E1462C\", \"#FF8777\", \"#0059A0\", \"#5F3893\"]\n",
    "filter = [\"ND\", \"LP725\", \"LP780\", \"SP775\"]\n",
    "fig = go.Figure()\n",
    "\n",
    "if label == \"pce\":\n",
    "    attr_pce = np.load(\"xai/results/eg_abs_global_pce.npy\")\n",
    "\n",
    "    fig.add_traces(\n",
    "        go.Bar(\n",
    "            x=filter,\n",
    "            y=attr_pce.sum(axis=1),\n",
    "            text=[\n",
    "                str(i) + \" ± \" + str(np.round(j, 3))\n",
    "                for i, j in zip(np.round(attr_pce.sum(axis=1), 2), attr_pce.std(axis=1))\n",
    "            ],\n",
    "            textposition=\"outside\",\n",
    "            textfont=dict(size=16, family=\"Helvetica\", color=\"rgb(0,0,0)\"),\n",
    "            marker_color=color,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(zerolinewidth=4, range=[0, 4.5])\n",
    "\n",
    "    f1 = scipy.stats.f_oneway(attr_pce[0], attr_pce[1], attr_pce[2], attr_pce[3], axis=0)[1]\n",
    "    f2 = scipy.stats.f_oneway(attr_pce[1], attr_pce[2], attr_pce[3], axis=0)[1]\n",
    "    fig = add_p_value_annotation(\n",
    "        fig,\n",
    "        array_columns=[[0, 3], [1, 3]],\n",
    "        p_value=[f1, f2],\n",
    "        _format=dict(interline=0.09, text_height=1.08, color=\"black\"),\n",
    "    )\n",
    "\n",
    "else:\n",
    "    attr_mth = np.load(\"xai/results/eg_abs_global_mth.npy\")\n",
    "\n",
    "    fig.add_traces(\n",
    "        go.Bar(\n",
    "            x=filter,\n",
    "            y=attr_mth.sum(axis=1),\n",
    "            text=[\n",
    "                str(int(i)) + \" ± \" + str(np.round(j, 3))\n",
    "                for i, j in zip(np.round(attr_mth.sum(axis=1)), attr_mth.std(axis=1))\n",
    "            ],\n",
    "            textposition=\"outside\",\n",
    "            textfont=dict(size=16, family=\"Helvetica\", color=\"rgb(0,0,0)\"),\n",
    "            marker_color=color,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(zerolinewidth=4, range=[0, 450])\n",
    "\n",
    "    t1 = scipy.stats.ttest_ind(a=attr_mth[1], b=attr_mth[3], equal_var=False)[1]\n",
    "    t2 = scipy.stats.ttest_ind(a=attr_mth[0], b=attr_mth[3], equal_var=False)[1]\n",
    "    fig = add_p_value_annotation(\n",
    "        fig,\n",
    "        array_columns=[[1, 3], [0, 3]],\n",
    "        p_value=[t1, t2],\n",
    "        _format=dict(interline=0.09, text_height=1.08, color=\"black\"),\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    "    legend_title=\" \",\n",
    "    template=\"plotly_white\",\n",
    "    height=400,\n",
    "    width=500,\n",
    "    font=dict(family=\"Helvetica\", color=\"#000000\", size=14),\n",
    ")\n",
    "\n",
    "fig.write_image(\"xai/images/\" + label + \"/1D/1D_global_filter.png\", scale=2)\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('perovskite')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9cd84acc5e6b29c782243490b26c04f4eba938e3194e8b2c75b711ae85fcc9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
