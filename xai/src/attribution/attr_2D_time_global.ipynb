{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir(Path(os.getcwd()).parents[2])\n",
    "os.getcwd()\n",
    "\n",
    "target = \"mth\"  # mth, pce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy\n",
    "import plotly.graph_objects as go\n",
    "import scipy.stats as ss\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from captum.attr import GradientShap, IntegratedGradients, GuidedBackprop, GuidedGradCam\n",
    "from captum.metrics import sensitivity_max, infidelity\n",
    "from os.path import join\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from data.perovskite_dataset import PerovskiteDataset2d_time\n",
    "from models.resnet import ResNet152, ResNet, BasicBlock, Bottleneck\n",
    "from data.augmentations.perov_2d import normalize as normalize_2d\n",
    "from base_model import seed_worker\n",
    "\n",
    "data_dir = os.getcwd() + \"/preprocessed\"\n",
    "\n",
    "data_dir = \"/home/l727n/Projects/Applied Projects/ml_perovskite/preprocessed\"\n",
    "\n",
    "if target == \"pce\":\n",
    "    checkpoint_dir = (\n",
    "        \"/home/l727n/E132-Projekte/Projects/Helmholtz_Imaging_ACVL/KIT-FZJ_2021_Perovskite/data_Jan_2022/checkpoints\"\n",
    "    )\n",
    "\n",
    "    path_to_checkpoint = join(checkpoint_dir, \"2D_time-epoch=999-val_MAE=0.000-train_MAE=0.725.ckpt\")\n",
    "else:\n",
    "    checkpoint_dir = \"/home/l727n/E132-Projekte/Projects/Helmholtz_Imaging_ACVL/KIT-FZJ_2021_Perovskite/data_Jan_2022/mT_checkpoints/checkpoints\"\n",
    "\n",
    "    path_to_checkpoint = join(checkpoint_dir, \"mT_2Dtime_RN18_full3-epoch=999-val_MAE=0.000-train_MAE=36.879.ckpt\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2D Model\n",
    "\n",
    "hypparams = {\n",
    "    \"dataset\": \"Perov_time_2d\",\n",
    "    \"dims\": 2,\n",
    "    \"bottleneck\": False,\n",
    "    \"name\": \"ResNet18\",\n",
    "    \"data_dir\": data_dir,\n",
    "    \"no_border\": False,\n",
    "    \"resnet_dropout\": 0.0,\n",
    "    \"stochastic_depth\": 0.0,\n",
    "    \"norm_target\": True if target == \"pce\" else False,\n",
    "    \"target\": \"PCE_mean\" if target == \"pce\" else \"meanThickness\",\n",
    "}\n",
    "\n",
    "model = ResNet.load_from_checkpoint(\n",
    "    path_to_checkpoint,\n",
    "    block=BasicBlock,\n",
    "    num_blocks=[2, 2, 2, 2],\n",
    "    num_classes=1,\n",
    "    hypparams=hypparams,\n",
    ")\n",
    "\n",
    "print(\"Loaded\")\n",
    "model.eval()\n",
    "\n",
    "train_set = PerovskiteDataset2d_time(\n",
    "    data_dir,\n",
    "    transform=normalize_2d(model.train_mean, model.train_std),\n",
    "    scaler=model.scaler,\n",
    "    no_border=False,\n",
    "    return_unscaled=False if target == \"pce\" else True,\n",
    "    label=\"PCE_mean\" if target == \"pce\" else \"meanThickness\",\n",
    ")\n",
    "\n",
    "test_set = PerovskiteDataset2d_time(\n",
    "    data_dir,\n",
    "    transform=normalize_2d(model.train_mean, model.train_std),\n",
    "    scaler=model.scaler,\n",
    "    no_border=False,\n",
    "    return_unscaled=False if target == \"pce\" else True,\n",
    "    label=\"PCE_mean\" if target == \"pce\" else \"meanThickness\",\n",
    "    fold=None,\n",
    "    split=\"test\",\n",
    "    val=False,\n",
    ")\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "loader = DataLoader(\n",
    "    torch.utils.data.ConcatDataset([train_set, test_set]),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    worker_init_fn=seed_worker,\n",
    "    persistent_workers=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select observation\n",
    "x_batch = next(iter(loader))\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_batch = model.predict(x_batch).flatten()\n",
    "\n",
    "x_batch = x_batch[0]\n",
    "\n",
    "# Init pertubation function for infidelity metric\n",
    "std_noise = 0.1\n",
    "\n",
    "\n",
    "def perturb_fn(inputs):\n",
    "    noise = torch.tensor(np.random.normal(0, std_noise, inputs.shape)).float()\n",
    "    return noise, inputs - noise\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Attribution Computation and Evaluation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = GradientShap(model)\n",
    "attr_sum = []\n",
    "infid_sum = []\n",
    "sens_sum = []\n",
    "\n",
    "for n in tqdm(range(x_batch.shape[0])):\n",
    "    attr = method.attribute(\n",
    "        x_batch[n].unsqueeze(0),\n",
    "        n_samples=80,\n",
    "        stdevs=0.001,\n",
    "        baselines=x_batch,\n",
    "        target=0,\n",
    "    )\n",
    "\n",
    "    attr_sum.append(attr.abs())\n",
    "\n",
    "    infid_sum.append(infidelity(model, perturb_fn, x_batch[n].unsqueeze(0), attr))\n",
    "    sens_sum.append(sensitivity_max(method.attribute, x_batch[n].unsqueeze(0), target=0, baselines=x_batch))\n",
    "\n",
    "attr_eg = torch.cat(attr_sum).mean(dim=0)\n",
    "infid_eg = torch.Tensor(infid_sum).mean()\n",
    "sens_eg = torch.Tensor(sens_sum).mean()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = IntegratedGradients(model)\n",
    "attr_sum = []\n",
    "infid_sum = []\n",
    "sens_sum = []\n",
    "\n",
    "for n in tqdm(range(x_batch.shape[0])):\n",
    "    attr, delta = method.attribute(\n",
    "        x_batch[n].unsqueeze(0),\n",
    "        baselines=x_batch[n].unsqueeze(0) * 0,\n",
    "        return_convergence_delta=True,\n",
    "    )\n",
    "\n",
    "    attr_sum.append(attr.abs())\n",
    "\n",
    "    infid_sum.append(infidelity(model, perturb_fn, x_batch[n].unsqueeze(0), attr))\n",
    "    sens_sum.append(\n",
    "        sensitivity_max(\n",
    "            method.attribute,\n",
    "            x_batch[n].unsqueeze(0),\n",
    "            target=0,\n",
    "            baselines=x_batch[n].unsqueeze(0) * 0,\n",
    "        )\n",
    "    )\n",
    "\n",
    "attr_ig = torch.cat(attr_sum).mean(dim=0)\n",
    "infid_ig = torch.Tensor(infid_sum).mean()\n",
    "sens_ig = torch.Tensor(sens_sum).mean()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guided Backprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = GuidedBackprop(model)\n",
    "attr_sum = []\n",
    "infid_sum = []\n",
    "sens_sum = []\n",
    "\n",
    "for n in tqdm(range(x_batch.shape[0])):\n",
    "    attr = method.attribute(x_batch[n].unsqueeze(0), target=0)\n",
    "\n",
    "    attr_sum.append(attr.abs())\n",
    "\n",
    "    infid_sum.append(infidelity(model, perturb_fn, x_batch[n].unsqueeze(0), attr))\n",
    "    sens_sum.append(sensitivity_max(method.attribute, x_batch[n].unsqueeze(0)))\n",
    "\n",
    "attr_gbp = torch.cat(attr_sum).mean(dim=0)\n",
    "infid_gbp = torch.Tensor(infid_sum).mean()\n",
    "sens_gbp = torch.Tensor(sens_sum).mean()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guided GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = GuidedGradCam(model, model.layer4)\n",
    "attr_sum = []\n",
    "infid_sum = []\n",
    "sens_sum = []\n",
    "\n",
    "for n in tqdm(range(x_batch.shape[0])):\n",
    "    attr = method.attribute(x_batch[n].unsqueeze(0), target=0)\n",
    "\n",
    "    attr_sum.append(attr.detach().abs())\n",
    "\n",
    "    infid_sum.append(infidelity(model, perturb_fn, x_batch[n].unsqueeze(0), attr))\n",
    "    sens_sum.append(sensitivity_max(method.attribute, x_batch[n].unsqueeze(0)))\n",
    "\n",
    "attr_ggc = torch.cat(attr_sum).mean(dim=0)\n",
    "infid_ggc = torch.Tensor(infid_sum).mean()\n",
    "sens_ggc = torch.Tensor(sens_sum).mean()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_title(title, subtitle=None, subtitle_font_size=12):\n",
    "    title = f\"<b>{title}</b>\"\n",
    "    if not subtitle:\n",
    "        return title\n",
    "    subtitle = f'<span style=\"font-size: {subtitle_font_size}px;\">{subtitle}</span>'\n",
    "    return f\"{title}<br>{subtitle}\"\n",
    "\n",
    "\n",
    "x = x_batch.mean(0)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=4,\n",
    "    cols=2,\n",
    "    vertical_spacing=0.05,\n",
    "    subplot_titles=(\n",
    "        format_title(\"\", \"ND\"),\n",
    "        format_title(\"\", \"LP725\"),\n",
    "        format_title(\"\", \"LP780\"),\n",
    "        format_title(\"\", \"SP775\"),\n",
    "        format_title(\"\", \" \"),\n",
    "        format_title(\"\", \" \"),\n",
    "        format_title(\"\", \" \"),\n",
    "        format_title(\"\", \" \"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "colors = [(0, \"#FFFFFF\"), (1, \"#5F3893\")]\n",
    "\n",
    "fig.add_trace(go.Heatmap(z=x.numpy()[0], colorscale=\"gray\", showscale=False), row=1, col=1)\n",
    "fig.add_trace(go.Heatmap(z=np.abs(attr_ggc[0]), colorscale=colors, showscale=False), row=3, col=1)\n",
    "\n",
    "fig.add_trace(go.Heatmap(z=x.numpy()[1], colorscale=\"gray\", showscale=False), row=1, col=2)\n",
    "fig.add_trace(go.Heatmap(z=np.abs(attr_ggc[1]), colorscale=colors, showscale=False), row=3, col=2)\n",
    "\n",
    "fig.add_trace(go.Heatmap(z=x.numpy()[2], colorscale=\"gray\", showscale=False), row=2, col=1)\n",
    "fig.add_trace(go.Heatmap(z=np.abs(attr_ggc[2]), colorscale=colors, showscale=False), row=4, col=1)\n",
    "\n",
    "fig.add_trace(go.Heatmap(z=x.numpy()[3], colorscale=\"gray\", showscale=False), row=2, col=2)\n",
    "fig.add_trace(go.Heatmap(z=np.abs(attr_ggc[3]), colorscale=colors, showscale=False), row=4, col=2)\n",
    "\n",
    "fig.update_yaxes(showticklabels=False)\n",
    "fig.update_xaxes(showticklabels=False)\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title_y=0.95,\n",
    "    title_x=0.01,\n",
    "    height=750,\n",
    "    width=400,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(showline=True, linewidth=0.5, linecolor=\"grey\", mirror=True)\n",
    "fig.update_yaxes(showline=True, linewidth=0.5, linecolor=\"grey\", mirror=True)\n",
    "\n",
    "fig.write_image(\"xai/images/\" + target + \"/2D_time/2D_attr_gl.png\", scale=2)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "def format_title(title, subtitle=None, font_size=14, subtitle_font_size=12):\n",
    "    title = f'<span style=\"font-size: {font_size}px;\"><b>{title}</b></span>'\n",
    "    if not subtitle:\n",
    "        return title\n",
    "    subtitle = f'<span style=\"font-size: {subtitle_font_size}px;\">{subtitle}</span>'\n",
    "    return f\"{title}<br>{subtitle}\"\n",
    "\n",
    "\n",
    "colors = [(0, \"#ffffff\"), (0.3, \"#ffffff\"), (1, \"#005C53\")]\n",
    "\n",
    "x = x_batch.mean(0)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=4,\n",
    "    cols=5,\n",
    "    vertical_spacing=0.1,\n",
    "    subplot_titles=(\n",
    "        format_title(\"ND\", \"Mean Original\", font_size=12),\n",
    "        format_title(\n",
    "            \"Expected Grad.\",\n",
    "            \"(\" + str(np.round(infid_eg.numpy(), 4)) + \", \" + str(np.round(sens_eg.numpy(), 4)) + \")\",\n",
    "            font_size=12,\n",
    "        ),\n",
    "        format_title(\n",
    "            \"Integrated Grad.\",\n",
    "            \"(\" + str(np.round(infid_ig.numpy(), 4)) + \", \" + str(np.round(sens_ig.numpy(), 4)) + \")\",\n",
    "            font_size=12,\n",
    "        ),\n",
    "        format_title(\n",
    "            \"Guided Backprob\",\n",
    "            \"(\" + str(np.round(infid_gbp.numpy(), 4)) + \", \" + str(np.round(sens_gbp.numpy(), 4)) + \")\",\n",
    "            font_size=12,\n",
    "        ),\n",
    "        format_title(\n",
    "            \"Guided GradCAM\",\n",
    "            \"(\" + str(np.round(infid_ggc.numpy(), 4)) + \", \" + str(np.round(sens_ggc.numpy(), 4)) + \")\",\n",
    "            font_size=12,\n",
    "        ),\n",
    "        format_title(\"LP725\", None, font_size=12),\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        format_title(\"LP780\", None, font_size=12),\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        format_title(\"SP775\", None, font_size=12),\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "for row in range(4):\n",
    "    for i in range(4):\n",
    "        fig.add_trace(go.Heatmap(z=x.numpy()[i], colorscale=\"gray\", showscale=False), row=row + 1, col=1)\n",
    "        fig.add_trace(go.Heatmap(z=attr_eg[i], colorscale=colors, showscale=False), row=row + 1, col=2)\n",
    "        fig.add_trace(go.Heatmap(z=attr_ig[i], colorscale=colors, showscale=False), row=row + 1, col=3)\n",
    "        fig.add_trace(go.Heatmap(z=attr_gbp[i], colorscale=colors, showscale=False), row=row + 1, col=4)\n",
    "        fig.add_trace(go.Heatmap(z=attr_ggc[i], colorscale=colors, showscale=False), row=row + 1, col=5)\n",
    "\n",
    "fig.update_yaxes(showticklabels=False)\n",
    "fig.update_xaxes(showticklabels=False)\n",
    "\n",
    "if target == \"pce\":\n",
    "    subtitle = \"Perovskite 1D Model / Target: PCE /(mean Infidelity, mean Sensitivity)\"\n",
    "else:\n",
    "    subtitle = \"Perovskite 1D Model / Target: Mean Thickness / (mean Infidelity, mean Sensitivity)\"\n",
    "\n",
    "fig.update_layout(\n",
    "    title=format_title(\n",
    "        \"Global Attribution: Mean abs. Attribution (n = \" + str(batch_size) + \") per Wavelength\",\n",
    "        subtitle,\n",
    "    ),\n",
    "    title_y=0.97,\n",
    "    title_x=0.1,\n",
    "    height=800,\n",
    "    width=800,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(showline=True, linewidth=0.5, linecolor=\"grey\", mirror=True)\n",
    "fig.update_yaxes(showline=True, linewidth=0.5, linecolor=\"grey\", mirror=True)\n",
    "\n",
    "fig.write_image(\"xai/images/\" + target + \"/2D_time/2D_cmp_global_wl.png\", scale=2)\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('perovskite')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9cd84acc5e6b29c782243490b26c04f4eba938e3194e8b2c75b711ae85fcc9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
